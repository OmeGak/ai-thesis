% !TEX root = ../thesis.tex

\chapter{Introduction}
\label{chap:intro}

\cleanchapterquote{‘Style’ is often something that ties the artist down and makes him look at things in one particular way, the same technique, the same formulas, year after year, sometimes for a whole lifetime.}{Pablo Picasso}{}


% ------------------------------------------------------------------------------

We can study a piece of art in terms of \emph{form} and \emph{content}.
When we talk about form we refer to the style, techniques, tools and materials used for the artwork; when we talk about content we refer to what the artwork actually depicts \cite{Esaak}.
While the two aspects are in principle independent, form and content in a finished artwork are tightly knitted together in a way that is hard to characterize them separately. Where does form end and content start when we look at the artwork? \cite{Xie2007}

This has been a traditional problem in pattern recognition.
The two concepts are often used in the machine learning literature to describe the task of extracting two intertwined features from an input, also often referred to as \emph{separation of style and content} \cite{Tenenbaum1997,Tenenbaum2000}.

Examples of intertwined features can often be seen, for instance, in character, speech and face recognition.
In character recognition, given an image depicting some text, the content is the words that make up the messages and the form is the handwriting style or typography if the text is printed; in speech recognition, the content of the audio is the phonemes that form what the speaker intend to transmit and the form is the accent the speaker presents; or in face recognition, the content of an image is the face and the form some other characterization such as lighting (e.g. natural light or artificial light).

Separation of form and content has barely been tackled in pattern recognition algorithms \cite{Karayev2014}, this being probably one of the reasons why they have performed so poorly until recently when faced with real-world scenarios, as I will argue next.
This pitfall is illustrated in early uses of speech recognition where the message was impossible to understand consistently due to slight variations in accent, pitch or tone in the speaker's voice.
When the interactive voice response systems, commonly used in call centers, started applying speech recognition technologies they clearly suffered from this: not only the vocabulary they could understand comprised only a few simple words, most of the time they had trouble understanding even those.

In contrast with those initial implementations, we now have access to consumer-ready services and applications that rely on complex pattern recognition like Apple's Siri voice assistant, Google's reverse image search or Facebook's automatic face tagging.
Pattern recognition has experienced such an evolution thanks to the quick development of deep learning techniques over the last decade.
Deep learning comprehends a set of algorithms, mostly based on the use of deep neural networks.
Said algorithms are capable of adapting to the variability of real-world input much better than most problem-specific algorithms to date and result in much higher rates of accuracy in most cases.

Deep neural networks in pattern recognition are not explicitly designed for solving separation of form and content, however.
Their goal is far less specific: to simply classify the input correctly.
Still, they seem to acquire an innate understanding of these concepts in the process, as \citeauthor{Gatys2015B}'s research \cite{Gatys2015B} proves.

\begin{figure}[htb]
  \includegraphics[width=\textwidth]{gfx/neural-style-composed}
  \caption{
    Neural Style algorithm implementation \cite{Johnson2015} results.
    \textbf{Top-left}: \textit{The Starry Night} by Vincent van Gogh, 1889, source of style.
    \textbf{Top-right}: night-time photograph of the Stanford campus, source of content.
    \textbf{Bottom}: Combination of style and content from the images above.
  }
  \label{fig:sec:intro:neural-style}
\end{figure}

\citeauthor{Gatys2015B} developed an algorithm capable of blending the style and content of two source images into a new one, this way effectively providing a holistic approach to a long-standing problem.
Instead of using a deep neural network trained for that precise purpose, the algorithm utilizes a network already trained in object recognition and, as the network processes an image, its content and style are extracted separately from the intermediate layers.
\autoref{fig:sec:intro:neural-style} shows the results from the style transfer capabilities of Neural Style \cite{Gatys2015B}.

These uncanny findings open the door for wondering about other underlying understanding deep neural networks may develop as side effects of a training process, how this can be used to better understand the human brain \cite{Yamins2016}, or what other applications similar methods can achieve.


% ------------------------------------------------------------------------------

\section{Goals}
\label{sec:intro:goals}

This thesis focuses on \citeauthor{Gatys2015B}'s Neural Style algorithm \cite{Gatys2015B} and its novel approach for separating of style and content from the optic of deep neural networks.
Being the field of Artificial Neural Networks extensive and in constant revision, in an effort to stay in topic the scope has been restricted to the following goals:

\begin{enumerate}
  \item Studying the motivation and challenges of the separation of style and content.
  \item Reviewing traditional approaches for the separation of style and content.
  \item Understanding Neural Style's approach for separating style and content.
  \item Exploring the conditions that enabled the development of Neural Style.
  \item Reflecting on the impact of methods applied in Neural Style.
  \item Finding novel applications that apply said methods.
  \item Proposing future work in the same line of research.
\end{enumerate}


% ------------------------------------------------------------------------------

\section{Thesis Structure}
\label{sec:intro:structure}

\textbf{\nameref{chap:theory}} \\[0.2em]
In Chapter~\ref{chap:theory} we give a theoretical introduction on artificial neural networks and deep learning as well as general concepts of used in particular implementations of networks that will be used in later chapters to further discuss separation of style and content.

\textbf{\nameref{chap:context}} \\[0.2em]
In Chapter~\ref{chap:context} we introduce the context that lead to the successful separation of style and content with deep neural networks covering: advances in object recognition, newly developed methods to visualize the internal representations in deep neural networks, and some background on the task of style transfer.

\textbf{\nameref{chap:system}} \\[0.2em]
In Chapter~\ref{chap:system} we present and discuss Neural Style \cite{Gatys2015B}, an algorithm that successfully separates content and style by using a deep neural network trained in object recognition.

\textbf{\nameref{sec:conclusion}} \\[0.2em]
Finally, in Chapter~\ref{sec:conclusion} we will muse about the implications of deep neural networks being able to extrapolate their past experience to tackle problems for which they weren't trained for.
